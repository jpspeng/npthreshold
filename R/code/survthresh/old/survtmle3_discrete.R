
#' Causal Survival Analysis using TMLE for discrete time-to-event variables
#'
#' This function performs causal survival analysis using targeted maximum likelihood estimation (TMLE) approach.
#' It estimates the treatment effect on survival outcomes while accounting for confounding variables and potential biases.
#' This method assumes the time-to-event variables are discrete with not too many levels.
#'
#' @param failure_time A numeric vector representing the time-to-event outcomes (e.g., time until death, failure, or censoring) for each observation.
#' The computational time and complexity of `survtmle_discrete` can significantly increase with the number of unique failure times.
#' For continuous or multi-valued discrete times, it is advisable to discretize the time-to-event variables into a grid of 20-30 time points.
#' Specifically, the dimension of the hazard estimation tasks generally scales linearly with the length of unique event times.
#' @param event_type A numeric vector of integers (0, 1, 2, ...) indicating the type of event for each observation. 0 is assumed to be censoring, and other values represent different types of failure events.
#' @param treatment A binary (0 or 1) or discrete (integer valued) treatment indicator vector indicating the treatment assignment for each observation.
#' @param covariates A named matrix specifying the names of potential counfounding variables in the dataset that should be used as adjustment covariates in the causal analysis.
#' @param weights A numeric vector of weights for each observation. Default is equal weights for all observations.
#' @param id A vector of unique identifiers for each observation. Default is a sequence from 1 to the length of 'treatment'.
#' @param learner.failure_time A \code{binomial} \code{\link[sl3]} learner object used for fitting the conditional hazard model for failure.
#' This learner is used as \code{binomial_learner} for \code{\link[sl3]{Lrnr_pooled_hazards}}.
#' Default uses auto ensemble learning by calling `causalutils::get_autoML()`.
#' @param learner.censoring_time A \code{binomial} \code{\link[sl3]{Lrnr_base}} learner object used for fitting conditional hazard model for censoring.
#' This learner is used as \code{binomial_learner} for \code{\link[sl3]{Lrnr_pooled_hazards}}.
#' Default uses auto ensemble learning by calling `causalutils::get_autoML()`.
#' @param learner.event_type A \code{binomial} \code{\link[sl3][Lrnr_base]} learner object used for fitting the conditional probability distribution for failure time of the failure event type.
#' For nonbinary categorical event type, this is used as \code{binomial_learner} in \code{\link[sl3]{Lrnr_independent_binomial}}.
#' Default uses auto ensemble learning by calling `causalutils::get_autoML()`.
#' @param learner.treatment A \code{binomial} \code{\link[sl3]{Lrnr_base}} learner object used for fitting the propensity score model for the treatment mechanism.
#' For nonbinary categorical treatment, this is used as \code{binomial_learner} in \code{\link[sl3]{Lrnr_independent_binomial}}.
#' Default uses auto ensemble learning by calling `causalutils::get_autoML()`.
#' @param cross_fit A logical value indicating whether to use cross-fitting (TRUE) or not (FALSE) when fitting the TMLE models.
#' See \code{\link[causalutils]{make_cross_fitted}}.
#' @param failure_time.stratify_by_time A logical value indicating whether to stratify the analysis by time when fitting the conditional hazard model for failure time.
#' @param censoring_time.stratify_by_time A logical value indicating whether to stratify the analysis by time when fitting the conditional hazard model for censoring time.
#' @param calibrate A logical value indicating whether to perform calibration of treatment effect estimates using cross-validation.
#' @param nfolds The number of folds to be used in cross-fitting. Default is 10.
#' @param max_iter The maximum number of iterations for the TMLE algorithm. Default is 200.
#' @param tol The convergence tolerance for the TMLE algorithm. Default is calculated based on the number of observations.
#' @param target_failure_time The target time points for which the treatment effect estimates will be computed. Default is the median of 'failure_time'.
#' @param target_treatment The target treatment values for which the treatment effect estimates will be computed. Default includes all unique values of 'treatment'.
#' @param target_event_type The target event types for which the treatment effect estimates will be computed. Default includes all unique non-zero values of 'event_type'.
#' @param verbose A logical value indicating whether to display progress and diagnostic messages during the computation. Default is TRUE.
#'
#' @return A list containing the estimated treatment effects and other relevant information from the TMLE analysis.
#'
#' @examples
#' # Generate example data
# set.seed(1234)
# n <- 500
# t0 <- 4
# a0 <- 1
# treatment <- rbinom(n, 1, 0.5)
# covariates <- data.frame(W1 = round(runif(n)), W2 = round(runif(n, 0, 2)))
# time <- round(1 + runif(n, 1, 4) + treatment + covariates$W1 + covariates$W2)
# status <- rbinom(n, 1, 0.5)
#'
#' # Perform causal survival analysis using autoML
#' result <- survtmle3_discrete(failure_time = time, event_type = status, treatment = treatment, covariates = covariates,
#' target_failure_time = t0,  target_treatment = a0)
#'
#' # add custom learner
#' result <- survtmle3_discrete(failure_time = time, event_type = status, treatment = treatment, covariates = covariates,
#' target_failure_time = t0,  target_treatment = a0,
#' learner.treatment = Lrnr_glmnet$new(),
#' learner.failure_time = Lrnr_gam$new(),
#' learner.censoring_time = Lrnr_gam$new(),
#' learner.event_type = Lrnr_earth$new(),
#' cross_fit = FALSE
#' )
#'
#'
#' @seealso
#' \code{\link{survtmle}}: The original survtmle package in R.
#'
#' @keywords survival analysis, causal inference, TMLE, treatment effect
#' @import sl3 data.table origami
#' @export
survtmle3_discrete <- function(failure_time, event_type, treatment, covariates,
                               weights = rep(1, length(treatment)),
                               id = 1:length(treatment),
                               learner.treatment,
                               learner.failure_time,
                               learner.censoring_time,
                               learner.event_type,
                               target_failure_time = median(failure_time),
                               target_treatment = sort(unique(treatment)),
                               target_event_type = setdiff(unique(event_type), 0),
                               failure_time.stratify_by_time = FALSE,
                               censoring_time.stratify_by_time = FALSE,
                               cross_fit = TRUE,
                               cross_validate = FALSE,
                               calibrate = TRUE,
                               autoML = FALSE,
                               nfolds = 10,
                               max_iter = 200,
                               tol = 0.1/sqrt(length(treatment))/log(length(treatment)),
                               verbose = TRUE
) {
    treatment <- as.numeric(as.vector(treatment))
    covariates <- as.matrix(covariates)
    failure_time <- as.numeric(as.vector(failure_time))
    event_type <- as.numeric(as.vector(event_type))
    fold_type <- ifelse(cross_fit , "validation", "full")

  if(autoML) {
    default.learner <- causalutils::get_autoML()
    cross_fit <- TRUE
  } else {
    default.learner <- NULL
  }

  if(is.null(learner.treatment)) learner.treatment <- default.learner
  if(is.null(learner.failure_time)) learner.failure_time <- default.learner
  if(is.null(learner.censoring_time)) learner.censoring_time <- default.learner
  if(is.null(learner.event_type)) learner.event_type <- default.learner




  n <- length(treatment)
  weights <- n*weights/sum(weights)
  target_event_type <- sort(target_event_type)
  target_treatment <- sort(target_treatment)
  target_failure_time <- sort(target_failure_time)
  # estimate total failure hazard
  # estimate distribution of event_type
  # estimate censoring hazard


  # make origami fold object
  if(is.numeric(nfolds)) {
    folds <- origami::folds_vfold(n, nfolds)
  }
  # convert to categorical learner
  learner.treatment <- Lrnr_independent_binomial$new(binomial_learner = learner.treatment)
  learner.event_type <- Lrnr_independent_binomial$new(binomial_learner = learner.event_type)

  if(cross_validate) {
    # in case, learner is a stack, use cross validation selector too.
    learner.failure_time <- Lrnr_cv$new(learner.failure_time)
    learner.censoring_time <- Lrnr_cv$new(learner.censoring_time)
    # add multinomial loss
    learner.event_type <- make_learner(Pipeline, Lrnr_cv$new(learner.event_type), Lrnr_cv_selector$new(loss_loglik_multinomial))
    learner.treatment <- make_learner(Pipeline, Lrnr_cv$new(learner.treatment), Lrnr_cv_selector$new(loss_loglik_multinomial))
  }
  # NOTE: Work around for bug when causalutils::Lrnr_stratified has binomial_learner being cross-validated
  if(failure_time.stratify_by_time) learner.failure_time <- causalutils::Lrnr_stratified$new(learner.failure_time, variable_stratify = "t")
  if(censoring_time.stratify_by_time) learner.censoring_time <- causalutils::Lrnr_stratified$new(learner.censoring_time, variable_stratify = "t")
  # Add cv-selectors
  if(cross_fit) learner.failure_time <- make_learner(Pipeline, learner.failure_time, Lrnr_cv_selector$new(loss_squared_error))
  if(cross_fit) learner.censoring_time <- make_learner(Pipeline, learner.censoring_time, Lrnr_cv_selector$new(loss_squared_error))

  # process covariate matrix
  if(!is.matrix(covariates)) covariates <- as.matrix(covariates)
  if(length(colnames(covariates)) == 0 || is.null(colnames(covariates))) {
    colnames(covariates) <- paste0("W", 1:ncol(covariates))
  }
  covariate_names <- colnames(covariates)
  treatment_levels <- sort(unique(treatment))
  event_type_levels <- sort(setdiff(unique(event_type), 0))
  time_grid <- 1:max(failure_time)



  # process survival data and convert to long format
  data <- data.table(failure_time, event_type, treatment, covariates, id, weights)
  data_long <- transform_data_to_long(data, node_list = list(failure_time = "failure_time", event_type = "event_type", id = "id"))
  # store failure types
  event_types <- setdiff(sort(unique(data$event_type)), 0) # censoring is treated as a failure type for computation
  # get pooled folds for cv
  pooled_folds <- origami::make_folds(
    cluster_ids = data_long$id,
    V = nfolds
  )
  ##################################################
  ### estimate nuisance functions using learners ###
  ##################################################

  #####
  # estimate propensity score:
  ####
  # TODO: nonbinary discrete treatments
  if(verbose) print("Estimating propensity score for treatment mechanism... ")
  data_treatment <- data
  levels_trt <- sort(unique(data$treatment))
  if(length(levels_trt) == 1){
    treatment.hat <- as.matrix(rep(1, nrow(data_treatment)))
  } else {
  data_treatment$treatment <- factor(data_treatment$treatment, levels = levels_trt)
  #treatment_task <-  sl3_Task$new(data_treatment, covariates = covariate_names, outcome = "treatment", id = "id", weights = "weights")

  treatment_task <-  (sl3_Task$new(data_treatment, covariates = covariate_names, outcome = "treatment", id = "id", weights = "weights", folds = folds, outcome_type = variable_type(type = "categorical", levels = levels_trt)))
  # Even if binary, Lrnr_independent_binomial predicts a matrix.
  #learner.treatment_cat <-  Lrnr_independent_binomial$new(binomial_learner = learner.treatment)
  learner.treatment_trained <- learner.treatment$train(treatment_task)

  #print(as.data.table(learner.treatment_cat_trained$predict_fold(treatment_task)))
  treatment.hat <- sl3::unpack_predictions(learner.treatment_trained$predict_fold(treatment_task, fold_type))
}




  ######
  # estimate total failure hazard
  ######
  if(verbose) print("Estimating conditional hazard function for failure mechanism...")
  # get indices for rows corresponding to individuals still at risk at time t.
  in_risk_set <- which(data_long$in_risk_set == 1)
  # make time-pooled task (use user-supplied weights and id)
  pooled_hazard_task <- suppressWarnings(sl3_Task$new(data_long, covariates = c(covariate_names, "treatment", "t"), outcome = "dN", weights = "weights", id = "id", folds = pooled_folds, time = "t"))
  # train on those at risk of censoring or failure

  learner.failure_trained <- learner.failure_time$train(pooled_hazard_task[in_risk_set])
  # predict on all observations
  total.hazard.hats <- do.call(cbind, lapply(treatment_levels, function(level) {
    tmp <- data_long
    tmp$treatment <- level
    pooled_hazard_task <- suppressWarnings(sl3_Task$new(tmp, covariates = c(covariate_names, "treatment", "t"), outcome = "dN", weights = "weights", id = "id", folds = pooled_folds, time = "t"))
    total.hazard.hat <-  learner.failure_trained$predict_fold(pooled_hazard_task, fold_type)
    return(total.hazard.hat)
  }))
  colnames(total.hazard.hats) <- as.character(treatment_levels)
  # store in list indexed by status

  hz <- colMeans(matrix(total.hazard.hats, ncol = length(time_grid)))
  tsk <- pooled_hazard_task[in_risk_set]
  #print(mean(tsk$Y))
  #print(weighted.mean(tsk$Y, tsk$weights))
  #print(hz)
  #print(cumprod(1-hz))

 c

  ######
  # estimate censoring hazard
  ######
  if(verbose) print("Estimating conditional hazard function for censoring mechanism...")
  if(any(event_type == 0)) {
    # get indices for rows corresponding to individuals still at risk at time t.
    in_risk_set <- which(data_long$in_risk_set == 1)
    # make time-pooled task (use user-supplied weights and id)
    pooled_hazard_task <- suppressWarnings(sl3_Task$new(data_long, covariates = c(covariate_names, "treatment", "t"), outcome = "dC", weights = "weights", id = "id", folds = pooled_folds))
    # train on those at risk of censoring or failure
    learner.censored_trained <- learner.censoring_time$train(pooled_hazard_task[in_risk_set])
    # predict on all observations
    censor.hazard.hats <- do.call(cbind, lapply(treatment_levels, function(level) {
      tmp <- data_long
      tmp$treatment <- level
      pooled_hazard_task <- suppressWarnings(sl3_Task$new(tmp, covariates = c(covariate_names, "treatment", "t"), outcome = "dC", weights = "weights", id = "id", folds = pooled_folds))
      censor.hazard.hat <- as.vector(unlist(learner.censored_trained$predict_fold(pooled_hazard_task, fold_type)))
      return(censor.hazard.hat)
    }))
    colnames(censor.hazard.hats) <- as.character(treatment_levels)
  } else {
    censor.hazard.hats <- do.call(cbind, lapply(treatment_levels, function(level) {
      return(rep(1, nrow(data_long)))
    }))
  }


  ######
  # estimate event_type distribution
  ######
  if(verbose) print("Estimating conditional distribution for failure type mechanism...")
  if(length(event_types) > 1) {

    outcome_type <- variable_type(type = "categorical", levels = event_type_levels)
    not_censored <- which(data$failure_time != 0)
    # set up learning tasks
    data_event_type <- data[, c(covariate_names, "treatment", "failure_time", "event_type", "weights", "id"), with = FALSE]
    sub_folds <- subset_folds(folds, not_censored)
    task_event_type_train <- suppressWarnings(sl3_Task$new(data_event_type[not_censored], covariates = c(covariate_names, "treatment", "failure_time"), outcome = "event_type", outcome_type = outcome_type, weights = "weights", id = "id", folds = sub_folds))
    # train and predict learner

    #learner.event_type.categorical <- Lrnr_independent_binomial$new(binomial_learner = learner.event_type)
    learner.event_type_trained <- learner.event_type$train(task_event_type_train)
    # matrix of event_type-specific estimates with columns following order of event_type_levels
    # at each time, get the probabilities.
    event_type.distr.hats <- lapply(treatment_levels, function(level) {
      event_type.distr.hats <- do.call(rbind, lapply(time_grid, function(t) {
        tmp <- data_event_type
        tmp$treatment <- level
        tmp$failure_time <- t
        task_event_type_predict <- suppressWarnings(sl3_Task$new(tmp, covariates = c(covariate_names, "treatment", "failure_time"), outcome = "event_type", outcome_type = outcome_type, weights = "weights", id = "id", folds = folds))
        event_type.distr.hats <- learner.event_type_trained$predict_fold(task_event_type_predict, fold_type)
        return(event_type.distr.hats)
      }))
      # predictions are packed
      event_type.distr.hats <- do.call(cbind, lapply(seq_along(event_type_levels), function(j) {
        # extract the jth index of each row
        as.vector(unlist(apply(event_type.distr.hats, 1, FUN = function(row){
          as.vector(unlist(row, use.names = FALSE)[[j]])
        })))
      }))
      colnames(event_type.distr.hats) <- as.character(event_type_levels)
      return(event_type.distr.hats)
    })
    names(event_type.distr.hats) <- as.character(treatment_levels)
  } else {
    event_type.distr.hats <- lapply(treatment_levels, function(level) {
      as.matrix(rep(1, nrow(data_long)))
    })
    names(event_type.distr.hats) <- as.character(treatment_levels)
  }
  # reformat



  # create list of nuisance estimates and parameters for tmle



  ##################################################
  ### targeted maximum likelihood estimation ###
  ##################################################

  # calibrate or adaptively truncate propensity scores away from zero
  if(calibrate) {
    truncation_method <- ifelse(length(unique(data_long$id)) >= 1000, "adaptive", "adaptive")
    } else {
      truncation_method <- "adaptive"
    }
  treatment.hat <- do.call(cbind, lapply(seq_along(treatment_levels), function(index){
    treatment.a0.hat <- causalutils::truncate_propensity(treatment.hat[,index], data$treatment, treatment_level = treatment_levels[index], truncation_method = truncation_method)
    return(treatment.a0.hat)
  }))
  colnames(treatment.hat) <- as.character(treatment_levels)

 a0 <- j0 <- 1
  S_failure_left <- long_hazard_to_survival_mats(total.hazard.hats, time_grid = time_grid, left_cont = TRUE)
  names(S_failure_left) <- as.character(treatment_levels)
  S_failure_left_a0 <- as.vector(S_failure_left[[as.character(a0)]])

  event_type.distr.hat_a0_j0 <- as.vector(event_type.distr.hats[[as.character(a0)]][, match(j0, event_type_levels)])
  total.hazard.hats_a0 <- total.hazard.hats[, match(a0, treatment_levels)]

  F_failure_a0_j0 <- S_failure_left_a0 * total.hazard.hats_a0 * event_type.distr.hat_a0_j0
  F_failure_a0_j0 <- matrix(F_failure_a0_j0, ncol = length(time_grid))

  F_failure_a0_j0 <- t(apply(F_failure_a0_j0, 1, cumsum))
  F_failure_a0_j0_t0 <- F_failure_a0_j0[, match(target_failure_time, time_grid), drop = FALSE]

  ests <- apply(as.matrix(F_failure_a0_j0_t0), 2, weighted.mean, weights)
  print(paste0("ests: ", ests))


  #t0=target_failure_time; a0=target_treatment; j0=target_event_type


  tmle.spec <- list(max_eps = 0.05,   data_long = data_long, treatment_levels = treatment_levels, event_type_levels= event_type_levels, treatment.hat = treatment.hat, censor.hazard.hats = censor.hazard.hats, total.hazard.hats = total.hazard.hats,  event_type.distr.hats = event_type.distr.hats, weights = weights)
  output <- as.data.table(expand.grid(target_treatment, target_event_type))
  names(output) <- c("treatment", "event_type")
  output$times <- list()
  output$estimates <- list()
  output$se <- list()
  output$EIF <- list()
  for(j0 in target_event_type) {
    for(a0 in target_treatment) {
      tmle.spec$target_event_type <- j0
      tmle.spec$target_failure_time <- target_failure_time
      tmle.spec$target_treatment <- a0
      # target distribution of event_type
      if(length(event_types) > 1) {
        out_event_type <- suppressWarnings(sl3:::call_with_args(.target_event_type_distr, tmle.spec, silent = TRUE))
        tmle.spec$event_type.distr.hats <- out_event_type$event_type.distr.hats
        score_event_type <- out_event_type$score
        print(paste0("type score solved: ", score_event_type))
      } else {
        out_event_type <- list(EIF = 0)
      }
      # target the failure hazard estimator
      converged_flag <- FALSE
      for(iter in 1:max_iter) {
        out_hazard <- suppressWarnings(sl3:::call_with_args(.target_failure_hazard, tmle.spec, silent = TRUE))
        tmle.spec$total.hazard.hats <- out_hazard$total.hazard.hats
        score_hazard <- out_hazard$score
        if(abs(score_hazard) <= tol) {
          print(paste0("failiure score solved: ", score_hazard))
         # print(iter)
        #  print(abs(score_hazard))
          converged_flag <- TRUE
          break
        }
      }
      total.hazard.hats <- tmle.spec$total.hazard.hats
      event_type.distr.hat_a0_j0 <- tmle.spec$event_type.distr.hat_a0_j0

      S_failure_left <- long_hazard_to_survival_mats(total.hazard.hats, time_grid = time_grid, left_cont = TRUE)
      names(S_failure_left) <- as.character(treatment_levels)
      S_failure_left_a0 <- as.vector(S_failure_left[[as.character(a0)]])

      event_type.distr.hat_a0_j0 <- as.vector(event_type.distr.hats[[as.character(a0)]][, match(j0, event_type_levels)])
      total.hazard.hats_a0 <- total.hazard.hats[, match(a0, treatment_levels)]

      F_failure_a0_j0 <- S_failure_left_a0 * total.hazard.hats_a0 * event_type.distr.hat_a0_j0
      F_failure_a0_j0 <- matrix(F_failure_a0_j0, ncol = length(time_grid))

      F_failure_a0_j0 <- t(apply(F_failure_a0_j0, 1, cumsum))
      F_failure_a0_j0_t0 <- F_failure_a0_j0[, match(target_failure_time, time_grid), drop = FALSE]

      ests <- apply(as.matrix(F_failure_a0_j0_t0), 2, weighted.mean, weights)
      EIF_W <- do.call(cbind,lapply(1:length(target_failure_time), function(index){
        comp <- F_failure_a0_j0_t0[, index] - ests[index]
        rep(weights*comp, length(time_grid))
      }))
      EIF <- out_hazard$EIF + as.vector(out_event_type$EIF) + EIF_W
      # sum over time points
      EIF <- apply(EIF, 2, function(eif){
        rowSums(matrix(eif, ncol = length(time_grid) , byrow = FALSE))
      })
      row_index <- output$event_type==j0 & output$treatment==a0
      ses <- apply(EIF, 2, sd)/sqrt(sum(weights))
      names(ests) <- paste0("time_", target_failure_time)
      names(ses) <- paste0("time_", target_failure_time)

      output[row_index, "EIF"] <- list(EIF)
      output[row_index, "estimates"] <- list(ests)
      output[row_index, "se"] <- list(ses)
      CI <- cbind(ests - qnorm(0.975) * ses, ests + qnorm(0.975) * ses)
      colnames(CI) <- c("CI_left", "CI_right")
      rownames(CI) <- paste0("time_", target_failure_time)
      output[row_index, "CI"] <- list(CI)
      output[row_index, "times"] <- list(target_failure_time)
    }
  }




  tmle.spec <- list(max_eps = 10,   data_long = data_long, treatment_levels = treatment_levels, event_type_levels= event_type_levels, treatment.hat = treatment.hat, censor.hazard.hats = censor.hazard.hats, total.hazard.hats = total.hazard.hats,  event_type.distr.hats = event_type.distr.hats, weights = weights)




  #CI <- data.table(cbind(output$estimate - qnorm(0.975) * output$se, output$estimate + qnorm(0.975) * output$se), conf = "95%")
  #names(CI) <- c("CI_left", "CI_right", "conf")

  return(output)

}
